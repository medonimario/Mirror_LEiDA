{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "import os\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `LEiDA_EEG_eigenvectors.m`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions - Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=6):\n",
    "    \"\"\"\n",
    "    Construct bandpass filter coefficients for a Butterworth filter.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    lowcut : float\n",
    "        Low cutoff frequency (Hz).\n",
    "    highcut : float\n",
    "        High cutoff frequency (Hz).\n",
    "    fs : float\n",
    "        Sampling frequency in Hz.\n",
    "    order : int, optional\n",
    "        The order of the Butterworth filter. Default is 6.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    b, a : ndarray\n",
    "        Numerator (b) and denominator (a) polynomials of the filter.\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def bandpass_filter(data, fs, lowcut, highcut, order=6):\n",
    "    \"\"\"\n",
    "    Apply zero-phase Butterworth bandpass filter to 1D data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray\n",
    "        One-dimensional time series data (e.g., one ROI).\n",
    "    fs : float\n",
    "        Sampling frequency in Hz.\n",
    "    lowcut : float\n",
    "        Low cutoff frequency (Hz).\n",
    "    highcut : float\n",
    "        High cutoff frequency (Hz).\n",
    "    order : int, optional\n",
    "        The order of the Butterworth filter. Default is 6.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    filtered_data : ndarray\n",
    "        Filtered time series, same shape as input.\n",
    "    \"\"\"\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    filtered_data = filtfilt(b, a, data)\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_leading_eigenvectors(data, fs, window_size, freq_band='alpha', verbose=True, do_plots=False):\n",
    "    \"\"\"\n",
    "    Replicates the MATLAB pipeline for:\n",
    "      1) Bandpass filtering a multi-channel EEG time series (per ROI).\n",
    "      2) Computing the Hilbert transform to extract instantaneous phases.\n",
    "      3) Computing dynamic phase-locking (dPL) matrices in non-overlapping windows.\n",
    "      4) Extracting the leading eigenvector from each dPL.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : ndarray\n",
    "        Shape [n_areas, n_timepoints]. Each row is the time series of one brain region.\n",
    "    fs : float\n",
    "        Sampling frequency in Hz.\n",
    "    window_size : int\n",
    "        Number of samples in each non-overlapping window (e.g., 250).\n",
    "    freq_band : str, optional\n",
    "        Which frequency band to use: 'alpha', 'beta', or 'gamma'. Default is 'alpha'.\n",
    "    verbose : bool, optional\n",
    "        If True, prints progress messages. Default is True.\n",
    "    do_plots : bool, optional\n",
    "        If True, shows intermediate plots (raw vs filtered signal, etc.) for debugging.\n",
    "        Default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lead_eigs : ndarray\n",
    "        Array of leading eigenvectors, shape [n_windows-2, n_areas].\n",
    "        (We skip the first and last window as in the MATLAB code.)\n",
    "    \"\"\"\n",
    "    \n",
    "    # --------------------------\n",
    "    # 1) Determine filter band\n",
    "    # --------------------------\n",
    "    if freq_band == 'alpha':\n",
    "        lowcut, highcut = 8, 12\n",
    "    elif freq_band == 'beta':\n",
    "        lowcut, highcut = 15, 25 # same as in other projects of mine\n",
    "    elif freq_band == 'gamma':\n",
    "        lowcut, highcut = 30, 80\n",
    "    else:\n",
    "        raise ValueError(\"freq_band must be 'alpha', 'beta', or 'gamma'.\")\n",
    "        \n",
    "    if verbose:\n",
    "        print(f\"Filtering data ({data.shape[0]} areas, {data.shape[1]} timepoints) \"\n",
    "              f\"from {lowcut} to {highcut} Hz, order=6.\")\n",
    "    \n",
    "    n_areas, T = data.shape\n",
    "    print(f\"N areas: {n_areas}, T: {T}\")\n",
    "    \n",
    "    # -------------------------------------------\n",
    "    # 2) De-mean and filter each ROI separately\n",
    "    # -------------------------------------------\n",
    "    # Subtract the mean per channel (as in the MATLAB code)\n",
    "    data_demean = data - np.mean(data, axis=1, keepdims=True)\n",
    "    \n",
    "    filtered_data = np.zeros_like(data_demean)\n",
    "    for i in range(n_areas):\n",
    "        filtered_data[i, :] = bandpass_filter(data_demean[i, :], fs,\n",
    "                                             lowcut, highcut, order=6)\n",
    "    \n",
    "    if do_plots:\n",
    "        # Plot an example channel (ROI 0) before and after filtering\n",
    "        t = np.arange(T) / fs\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(t, data_demean[0, :], label='Raw (demeaned)', alpha=0.7)\n",
    "        plt.plot(t, filtered_data[0, :], label='Filtered', alpha=0.7)\n",
    "        plt.xlim([0, min(10.0, t[-1])])  # zoom in on the first second\n",
    "        plt.legend()\n",
    "        plt.title(\"ROI 0: Before and After Filtering\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.show()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # 3) Compute Hilbert transform to get instantaneous phase\n",
    "    # --------------------------------------------------------\n",
    "    analytic_signal = hilbert(filtered_data, axis=1)\n",
    "    phases = np.angle(analytic_signal)\n",
    "    \n",
    "    if do_plots:\n",
    "        # Plot example channel's phase\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(t, phases[0, :], label='Phase (ROI 0)')\n",
    "        plt.title(\"Instantaneous Phase of Filtered Signal (ROI 0)\")\n",
    "        plt.xlabel(\"Time (s)\")\n",
    "        plt.ylabel(\"Phase (radians)\")\n",
    "        plt.xlim([0, min(10.0, t[-1])])  # zoom in\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    # -----------------------------------\n",
    "    # 4) Windowing & dynamic phase-locking\n",
    "    # -----------------------------------\n",
    "    # In MATLAB code:\n",
    "    #   repArray = 1:window_size:size(data,2)\n",
    "    #   for t = 2 : (repetitions-1)\n",
    "    # so effectively we skip the first and last windows.\n",
    "    # We'll do the same to match their indexing logic.\n",
    "    \n",
    "    repArray = np.arange(0, T, window_size)  # e.g. [0, 250, 500, ...]\n",
    "    repetitions = len(repArray)\n",
    "    if T % window_size != 0 and verbose:\n",
    "        print(\"Warning: discarding last incomplete window since T not multiple of window_size.\")\n",
    "    \n",
    "    lead_eig_list = []\n",
    "    example_iFC = None\n",
    "    example_V1 = None\n",
    "    \n",
    "    for t_idx in range(1, repetitions - 1):\n",
    "        start_idx = repArray[t_idx - 1]\n",
    "        end_idx = repArray[t_idx]\n",
    "        \n",
    "        # Build iFC (dynamic phase-locking matrix) for this window\n",
    "        iFC = np.zeros((n_areas, n_areas))\n",
    "        for n in range(n_areas):\n",
    "            for p in range(n_areas):\n",
    "                # Extract the phase differences and compute the average of cos(differences)\n",
    "                diffs = phases[n, start_idx:end_idx] - phases[p, start_idx:end_idx]\n",
    "                iFC[n, p] = np.mean(np.cos(diffs))\n",
    "        \n",
    "        # --------------------------------\n",
    "        # 5) Leading eigenvector of iFC\n",
    "        # --------------------------------\n",
    "        # For a symmetric real matrix iFC, we can use np.linalg.eigh.\n",
    "        vals, vecs = np.linalg.eigh(iFC)\n",
    "        # Largest eigenvalue => last entry if ascending\n",
    "        idx_max = np.argmax(vals)  # or we can just take [-1] if guaranteed sorted\n",
    "        V1 = vecs[:, idx_max]\n",
    "        lead_eig_list.append(V1)\n",
    "\n",
    "        if t_idx == 10:\n",
    "            example_iFC = iFC.copy()\n",
    "            example_V1 = V1.copy()\n",
    "    \n",
    "    lead_eigs = np.array(lead_eig_list)  # shape [n_windows - 2, n_areas]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Computed {lead_eigs.shape[0]} leading eigenvectors \"\n",
    "              f\"for {n_areas} areas with window_size={window_size}.\")\n",
    "    \n",
    "    if do_plots and example_iFC is not None:\n",
    "        # Plot the phase-locking matrix (dPL) as an image\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.imshow(example_iFC, cmap='bwr', aspect='auto', vmin=-1, vmax=1)\n",
    "        plt.colorbar(label='Phase Coherence (mean cos(diff))')\n",
    "        plt.title(\"Example Dynamic Phase-Locking Matrix (dPL)\")\n",
    "        plt.xlabel(\"Brain Region (ROI index)\")\n",
    "        plt.ylabel(\"Brain Region (ROI index)\")\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot the corresponding leading eigenvector with sign preserved.\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        markerline, stemlines, baseline = plt.stem(np.arange(n_areas), example_V1)\n",
    "        plt.setp(markerline, marker='o', markersize=6, color='b')\n",
    "        plt.setp(stemlines, color='b')\n",
    "        plt.title(\"Leading Eigenvector (with sign) from Example dPL\")\n",
    "        plt.xlabel(\"Brain Region (ROI index)\")\n",
    "        plt.ylabel(\"Eigenvector Component\")\n",
    "        plt.show()\n",
    "\n",
    "    return lead_eigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_example_eeg_mat(file_path):\n",
    "    \"\"\"\n",
    "    Load the exampleSourceEEG_8.mat file containing EEG data for 8 participants.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        Path to the .mat file.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    data_list : list of ndarray\n",
    "        List of length 8, where each element is an EEG data matrix of shape (N_areas, T).\n",
    "    \"\"\"\n",
    "    mat_contents = scipy.io.loadmat(file_path)\n",
    "    \n",
    "    # Extract participants (p1, p2, ..., p8)\n",
    "    participants = [mat_contents[f'p{i+1}'] for i in range(8)]\n",
    "    \n",
    "    # Check consistency\n",
    "    for i, data in enumerate(participants):\n",
    "        if data.ndim != 2:\n",
    "            raise ValueError(f\"Participant p{i+1} data is not 2D (found shape {data.shape}).\")\n",
    "    \n",
    "    print(f\"Loaded EEG data for {len(participants)} participants.\")\n",
    "    return participants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ Path to the provided dataset (update the path as needed)\n",
    "file_path = '../data/LEiDA_EEG/exampleSourceEEG_8.mat'\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    raise FileNotFoundError(f\"File '{file_path}' not found. Please check the path.\")\n",
    "\n",
    "# Load the dataset\n",
    "participants_data = load_example_eeg_mat(file_path)\n",
    "\n",
    "# Parameters\n",
    "fs = 250           # Sampling frequency in Hz\n",
    "window_size = 50  # Window size in samples (200 ms windows)\n",
    "freq_band = 'alpha'  # Frequency band: 'alpha', 'beta', 'gamma'\n",
    "\n",
    "# Process each participant\n",
    "all_leading_eigenvectors = []\n",
    "for i, data in enumerate(participants_data):\n",
    "    print(f\"\\n--- Processing Participant {i+1} ---\")\n",
    "    lead_vecs = compute_leading_eigenvectors(data, \n",
    "                                             fs, \n",
    "                                             window_size, \n",
    "                                             freq_band, \n",
    "                                             verbose=True, \n",
    "                                             do_plots=True)\n",
    "    all_leading_eigenvectors.append(lead_vecs)\n",
    "\n",
    "print(\"\\n✅ Processing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(participants_data[0].shape)\n",
    "\n",
    "print(all_leading_eigenvectors[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. K-means clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_leida_kmeans(coll_eigenvectors, K, n_init=50, max_iter=200, random_state=None):\n",
    "    \"\"\"\n",
    "    Replicates the essential steps of LEiDA_EEG_kmeans.m in Python:\n",
    "      - K-means with 'sqeuclidean' (which is the usual sum-of-squares in scikit-learn).\n",
    "      - Re-label clusters by size (largest cluster -> cluster #0, second largest -> #1, etc.).\n",
    "    Returns a dict similar to the MATLAB struct.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Run k-means with the given K\n",
    "    #    'algorithm'='lloyd' is standard, inertia_ is sum of squared distances\n",
    "    kmeans = KMeans(n_clusters=K,\n",
    "                    n_init=n_init,\n",
    "                    max_iter=max_iter,\n",
    "                    random_state=random_state,\n",
    "                    # scikit-learn uses Euclidean distance (which is effectively\n",
    "                    # the same \"sqeuclidean\" objective for sum-of-squared-distances).\n",
    "                   )\n",
    "    kmeans.fit(coll_eigenvectors)\n",
    "\n",
    "    # labels_: shape [n_samples,], each sample assigned cluster 0..K-1\n",
    "    old_labels = kmeans.labels_\n",
    "    centers = kmeans.cluster_centers_\n",
    "\n",
    "    # 2) Sort clusters by descending frequency (size)\n",
    "    #    Count how many rows ended up in each cluster\n",
    "    counts = np.bincount(old_labels, minlength=K)  # shape [K]\n",
    "    # Sort them descending by cluster size\n",
    "    ind_sort = np.argsort(counts)[::-1]  # largest cluster first\n",
    "    # Create a mapping array: cluster 'ind_sort[0]' -> new label 0, etc.\n",
    "    cluster_map = np.zeros(K, dtype=int)\n",
    "    for new_label, old_label in enumerate(ind_sort):\n",
    "        cluster_map[old_label] = new_label\n",
    "\n",
    "    # 3) Re-label the assignments according to cluster size\n",
    "    new_labels = cluster_map[old_labels]\n",
    "\n",
    "    # 4) Reorder the cluster centers the same way\n",
    "    new_centers = centers[ind_sort, :]\n",
    "\n",
    "    # For completeness, we can compute per-point distance to each centroid\n",
    "    # to replicate \"D\" in MATLAB (which is the distance from each point to each centroid).\n",
    "    # By default, KMeans.transform() returns the Euclidean distance to each cluster center,\n",
    "    # i.e. shape [n_samples, K]. For \"sqeuclidean\" in MATLAB, one might want to square these\n",
    "    # distances manually if an exact match is needed. Below we keep them Euclidean:\n",
    "    distances = kmeans.transform(coll_eigenvectors)\n",
    "\n",
    "    # If you want the sum of squared distances to each cluster center, can do:\n",
    "    # sumd_per_cluster = []\n",
    "    # for c in range(K):\n",
    "    #     # find points in cluster c\n",
    "    #     mask = (new_labels == c)\n",
    "    #     # sum of squared distances\n",
    "    #     # (If you want the 'sqeuclidean' version, do distances[mask,c]**2)\n",
    "    #     ssd = np.sum(distances[mask, c] ** 2)\n",
    "    #     sumd_per_cluster.append(ssd)\n",
    "\n",
    "    # Return results in a dictionary (mimicking MATLAB struct)\n",
    "    return {\n",
    "        'IDX': new_labels,           # cluster labels (time course) after re-labeling\n",
    "        'C': new_centers,            # cluster centroids\n",
    "        'counts': counts[ind_sort],  # cluster sizes in descending order\n",
    "        'distances': distances,      # distance of each point to each centroid\n",
    "        # optionally include sum-of-distances if needed\n",
    "        # 'SUMD': sumd_per_cluster,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_kmeans_3d_pca(collEigenvectors, labels, centers, title=\"K-means Clusters in PCA Space\"):\n",
    "    \"\"\"\n",
    "    Project eigenvector data (collEigenvectors) onto 3 principal components,\n",
    "    then scatter-plot them in 3D, color-coded by cluster label. The cluster\n",
    "    centers are also projected and plotted as black-edged triangles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    collEigenvectors : ndarray, shape (n_samples, n_features)\n",
    "        All collated eigenvectors that were clustered.\n",
    "    labels : ndarray, shape (n_samples,)\n",
    "        Integer cluster labels for each row in collEigenvectors.\n",
    "    centers : ndarray, shape (K, n_features)\n",
    "        The cluster centroids (in original feature space).\n",
    "    title : str\n",
    "        Title for the plot (optional).\n",
    "    \"\"\"\n",
    "    # 1) Run PCA to reduce dimensionality to 3\n",
    "    pca = PCA(n_components=3)\n",
    "    X_pca = pca.fit_transform(collEigenvectors)   # shape: [n_samples, 3]\n",
    "    centers_pca = pca.transform(centers)          # shape: [K, 3]\n",
    "    \n",
    "    # 2) Plot the data, color-coded by cluster label\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        X_pca[:, 0], \n",
    "        X_pca[:, 1], \n",
    "        X_pca[:, 2],\n",
    "        c=labels,                # use cluster labels as color\n",
    "        cmap='rainbow',\n",
    "        alpha=0.6\n",
    "    )\n",
    "    \n",
    "    # 3) Plot the cluster centers as bigger, distinct markers\n",
    "    K = centers.shape[0]\n",
    "    ax.scatter(\n",
    "        centers_pca[:, 0], \n",
    "        centers_pca[:, 1], \n",
    "        centers_pca[:, 2],\n",
    "        c=np.arange(K),         # color them using the same colormap but indexed by cluster\n",
    "        cmap='rainbow',\n",
    "        marker='^',\n",
    "        s=200,\n",
    "        edgecolors='k',\n",
    "        label='Cluster centers'\n",
    "    )\n",
    "    \n",
    "    # 4) Tidy up the figure\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_zlabel('PC3')\n",
    "    ax.set_title(title)\n",
    "    # Colorbar with cluster label indices\n",
    "    cbar = fig.colorbar(scatter, ax=ax, fraction=0.03, pad=0.07)\n",
    "    cbar.set_label(\"Cluster Label\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Collate all subject data into one big array\n",
    "collEigenvectors = np.vstack(all_leading_eigenvectors)\n",
    "print(\"Shape of collEigenvectors:\", collEigenvectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# 2) Try k-means with k from e.g. 4..10\n",
    "rangeK = range(4, 11)\n",
    "kmeans_solutions = {}\n",
    "\n",
    "for k in rangeK:\n",
    "    print(f\"Running k-means for K={k} ...\")\n",
    "    res = run_leida_kmeans(collEigenvectors, K=k, n_init=50, max_iter=200)\n",
    "    kmeans_solutions[k] = res\n",
    "    plot_kmeans_3d_pca(collEigenvectors, res['IDX'], res['C'], title=f\"K-means Clusters for K={k}\")\n",
    "    print(f\"Finished K={k}.\")\n",
    "    print(\"Cluster sizes:\", res['counts'])\n",
    "    print(\"Cluster centers shape:\", res['C'].shape)\n",
    "    print(\"Cluster labels shape:\", res['IDX'].shape)\n",
    "    print(\"Distances shape:\", res['distances'].shape)\n",
    "    print(\"------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n✅ K-means clustering complete!\")\n",
    "print(f\"Results for K={k}:\\n\", kmeans_solutions[k].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments (IDX):\", kmeans_solutions[k]['IDX'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster centers (C):\", kmeans_solutions[k]['C'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Cluster counts:\", kmeans_solutions[k]['counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib widget\n",
    "# Choose fixed K\n",
    "chosen_k = 10\n",
    "solution = kmeans_solutions[chosen_k]\n",
    "all_labels = solution['IDX']  # shape [total_time_points]\n",
    "\n",
    "# Determine subject-specific time window lengths\n",
    "subject_lengths = [arr.shape[0] for arr in all_leading_eigenvectors]\n",
    "num_subjects = len(subject_lengths)\n",
    "\n",
    "# Generate colormap for the states\n",
    "palette = sns.color_palette(\"husl\", chosen_k)\n",
    "\n",
    "# Plot for each participant\n",
    "fig, axes = plt.subplots(num_subjects, 1, figsize=(10, 2 * num_subjects), sharex=True, sharey=True)\n",
    "\n",
    "start_idx = 0\n",
    "for i, (length_i, ax) in enumerate(zip(subject_lengths, axes)):\n",
    "    end_idx = start_idx + length_i\n",
    "    subj_labels = all_labels[start_idx:end_idx]  # Get states for this subject\n",
    "\n",
    "    # Use a scatter plot where color represents the state\n",
    "    ax.scatter(range(length_i), subj_labels, c=[palette[l] for l in subj_labels], s=10, alpha=0.8)\n",
    "    ax.set_ylabel(f\"Subj {i+1}\")\n",
    "    ax.set_yticks(range(chosen_k))  # Ensure all labels appear\n",
    "    start_idx = end_idx\n",
    "\n",
    "# Final plot formatting\n",
    "axes[-1].set_xlabel(\"Time Window\")\n",
    "fig.suptitle(f\"State Transitions for Each Participant (K={chosen_k})\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Compute state occurrence probabilities per subject\n",
    "subject_probabilities = []\n",
    "\n",
    "start_idx = 0\n",
    "for length_i in subject_lengths:\n",
    "    end_idx = start_idx + length_i\n",
    "    subj_labels = all_labels[start_idx:end_idx]  # Get labels for this subject\n",
    "    prob_vec = [(subj_labels == c).mean() for c in range(chosen_k)]  # Compute probability\n",
    "    subject_probabilities.append(prob_vec)\n",
    "    start_idx = end_idx\n",
    "\n",
    "subject_probabilities = np.array(subject_probabilities)  # shape: [num_subjects, chosen_k]\n",
    "\n",
    "# Plot grouped bar chart\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "x = np.arange(num_subjects)  # Subject indices\n",
    "width = 0.15  # Width of each bar\n",
    "\n",
    "palette = sns.color_palette(\"husl\", chosen_k)\n",
    "\n",
    "for c in range(chosen_k):\n",
    "    ax.bar(x + c * width, subject_probabilities[:, c], width, label=f\"State {c}\", color=palette[c])\n",
    "\n",
    "ax.set_xlabel(\"Subjects\")\n",
    "ax.set_ylabel(\"Occurrence Probability\")\n",
    "ax.set_title(f\"State Occurrence Probability for Each Subject (K={chosen_k})\")\n",
    "ax.set_xticks(x + (chosen_k / 2) * width)\n",
    "ax.set_xticklabels([f\"Subj {i+1}\" for i in range(num_subjects)])\n",
    "ax.legend(title=\"Brain State\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bottoms = np.zeros(num_subjects)\n",
    "\n",
    "for c in range(chosen_k):\n",
    "    ax.bar(x, subject_probabilities[:, c], bottom=bottoms, label=f\"State {c}\", color=palette[c])\n",
    "    bottoms += subject_probabilities[:, c]  # Update bottom for stacking\n",
    "\n",
    "ax.set_xlabel(\"Subjects\")\n",
    "ax.set_ylabel(\"Proportion of Time in State\")\n",
    "ax.set_title(f\"State Distribution per Subject (K={chosen_k})\")\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f\"Subj {i+1}\" for i in range(num_subjects)])\n",
    "ax.legend(title=\"Brain State\", bbox_to_anchor=(1,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame for seaborn heatmap\n",
    "df = pd.DataFrame(subject_probabilities, columns=[f\"State {i}\" for i in range(chosen_k)])\n",
    "df.index = [f\"Subj {i+1}\" for i in range(num_subjects)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(df, annot=True, cmap=\"Blues\", linewidths=0.5)\n",
    "plt.title(f\"Occurrence Probability Heatmap (K={chosen_k})\")\n",
    "plt.xlabel(\"Brain State\")\n",
    "plt.ylabel(\"Subjects\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def compute_dwell_time(all_labels, subject_lengths, chosen_k):\n",
    "    \"\"\"\n",
    "    Compute the dwell time for each state and each subject.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    all_labels : ndarray\n",
    "        Cluster assignments for all time windows across subjects.\n",
    "    subject_lengths : list\n",
    "        Number of time windows per subject.\n",
    "    chosen_k : int\n",
    "        Number of clusters (states).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dwell_times : ndarray, shape [num_subjects, chosen_k]\n",
    "        Average dwell time per subject for each state.\n",
    "    \"\"\"\n",
    "\n",
    "    dwell_times = []\n",
    "\n",
    "    start_idx = 0\n",
    "    for length_i in subject_lengths:\n",
    "        end_idx = start_idx + length_i\n",
    "        subj_labels = all_labels[start_idx:end_idx]\n",
    "\n",
    "        # Compute dwell time for each state\n",
    "        dwell_time_per_state = []\n",
    "        for state in range(chosen_k):\n",
    "            # Find indices where state appears\n",
    "            state_indices = np.where(subj_labels == state)[0]\n",
    "\n",
    "            if len(state_indices) == 0:\n",
    "                dwell_time_per_state.append(0)  # No occurrence of this state\n",
    "                continue\n",
    "\n",
    "            # Identify state runs\n",
    "            diff = np.diff(state_indices)\n",
    "            run_starts = np.where(diff > 1)[0]  # Where gaps exist in indices\n",
    "            num_runs = len(run_starts) + 1  # Total runs including last\n",
    "\n",
    "            # Average dwell time for this state\n",
    "            dwell_time = len(state_indices) / num_runs\n",
    "            dwell_time_per_state.append(dwell_time)\n",
    "\n",
    "        dwell_times.append(dwell_time_per_state)\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return np.array(dwell_times)  # Shape: [num_subjects, chosen_k]\n",
    "\n",
    "\n",
    "# Compute dwell times\n",
    "dwell_times = compute_dwell_time(all_labels, subject_lengths, chosen_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=dwell_times, palette=\"husl\")\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Dwell Time (avg. time windows in state)\")\n",
    "plt.title(f\"Dwell Time per State (K={chosen_k})\")\n",
    "plt.xticks(ticks=np.arange(chosen_k), labels=[f\"State {i}\" for i in range(chosen_k)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(dwell_times, annot=True, cmap=\"Blues\", linewidths=0.5)\n",
    "plt.xlabel(\"Brain State\")\n",
    "plt.ylabel(\"Subjects\")\n",
    "plt.title(f\"Dwell Time Heatmap (K={chosen_k})\")\n",
    "plt.xticks(ticks=np.arange(chosen_k), labels=[f\"State {i}\" for i in range(chosen_k)])\n",
    "plt.yticks(ticks=np.arange(len(subject_lengths)), labels=[f\"Subj {i+1}\" for i in range(len(subject_lengths))])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compute_transition_matrices(all_labels, subject_lengths, chosen_k):\n",
    "    \"\"\"\n",
    "    Compute transition matrices for each subject.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_labels : ndarray\n",
    "        Cluster assignments for all time windows across subjects.\n",
    "    subject_lengths : list\n",
    "        Number of time windows per subject.\n",
    "    chosen_k : int\n",
    "        Number of clusters (states).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    transition_matrices : ndarray, shape [num_subjects, chosen_k, chosen_k]\n",
    "        State transition matrices per subject.\n",
    "    \"\"\"\n",
    "\n",
    "    num_subjects = len(subject_lengths)\n",
    "    transition_matrices = np.zeros((num_subjects, chosen_k, chosen_k))\n",
    "\n",
    "    start_idx = 0\n",
    "    for subj in range(num_subjects):\n",
    "        length_i = subject_lengths[subj]\n",
    "        end_idx = start_idx + length_i\n",
    "        subj_labels = all_labels[start_idx:end_idx]  # Get labels for this subject\n",
    "\n",
    "        # Build transition count matrix\n",
    "        for t in range(len(subj_labels) - 1):\n",
    "            from_state = subj_labels[t]\n",
    "            to_state = subj_labels[t + 1]\n",
    "            transition_matrices[subj, from_state, to_state] += 1\n",
    "\n",
    "        # Normalize to get transition probabilities\n",
    "        row_sums = transition_matrices[subj].sum(axis=1, keepdims=True)\n",
    "        row_sums[row_sums == 0] = 1  # Avoid division by zero\n",
    "        transition_matrices[subj] /= row_sums\n",
    "\n",
    "        start_idx = end_idx\n",
    "\n",
    "    return transition_matrices\n",
    "\n",
    "# Compute transition matrices\n",
    "transition_matrices = compute_transition_matrices(all_labels, subject_lengths, chosen_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_transition_matrix = np.mean(transition_matrices, axis=0)  # Mean over subjects\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(avg_transition_matrix, annot=True, cmap=\"Blues\", linewidths=0.5, fmt=\".2f\")\n",
    "plt.xlabel(\"To State\")\n",
    "plt.ylabel(\"From State\")\n",
    "plt.title(f\"Average State Transition Matrix (K={chosen_k})\")\n",
    "plt.xticks(ticks=np.arange(chosen_k), labels=[f\"{i}\" for i in range(chosen_k)])\n",
    "plt.yticks(ticks=np.arange(chosen_k), labels=[f\"{i}\" for i in range(chosen_k)])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4, len(subject_lengths)//4, figsize=(16, 24), sharex=True, sharey=True)\n",
    "flat_axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(flat_axes):\n",
    "    if i < len(subject_lengths):\n",
    "        sns.heatmap(transition_matrices[i], ax=ax, annot=True, cmap=\"Blues\", linewidths=0.5, fmt=\".2f\")\n",
    "        ax.set_title(f\"Subj {i+1}\")\n",
    "        ax.set_xlabel(\"To State\")\n",
    "        ax.set_ylabel(\"From State\")\n",
    "        ax.set_xticks(np.arange(chosen_k))\n",
    "        ax.set_yticks(np.arange(chosen_k))\n",
    "        ax.set_xticklabels([f\"{j}\" for j in range(chosen_k)])\n",
    "        ax.set_yticklabels([f\"{j}\" for j in range(chosen_k)])\n",
    "    else:\n",
    "        ax.axis('off')  # Hide empty subplots\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 3) Probability of each cluster for each subject\n",
    "# # We'll illustrate for k=6 as an example:\n",
    "# chosen_k = 6\n",
    "# res_chosen = kmeans_solutions[chosen_k]\n",
    "# all_labels = res_chosen['IDX']  # shape [total_time_points]\n",
    "\n",
    "# # figure out how many time windows each subject had:\n",
    "# subject_lengths = [arr.shape[0] for arr in all_leading_eigs_per_subject]\n",
    "# subject_probabilities = []\n",
    "\n",
    "# start_idx = 0\n",
    "# for i, length_i in enumerate(subject_lengths):\n",
    "#     end_idx = start_idx + length_i\n",
    "#     # cluster labels for subject i\n",
    "#     subj_labels = all_labels[start_idx:end_idx]\n",
    "#     # probability of each cluster c in 0..(k-1)\n",
    "#     # note: after re-labeling in run_leida_kmeans, clusters are 0..k-1\n",
    "#     prob_vec = [(subj_labels == c).mean() for c in range(chosen_k)]\n",
    "#     subject_probabilities.append(prob_vec)\n",
    "#     start_idx = end_idx\n",
    "\n",
    "# subject_probabilities = np.array(subject_probabilities)  # shape [num_subjects, chosen_k]\n",
    "# print(\"Probability that each subject belongs to each cluster:\\n\", subject_probabilities)\n",
    "\n",
    "# # (At this point, you would do your group-level stats or store them,\n",
    "# # just like the MATLAB code does with P(s,k,c).)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
