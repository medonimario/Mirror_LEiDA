{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Source Reconstruction Pipeline\n",
    "\n",
    "This notebook outlines a step-by-step procedure to:\n",
    "1. Load and prepare EEG data from an EEGLAB `.set` file.\n",
    "2. Compute a forward solution using MNEâ€™s `fsaverage` template.\n",
    "3. Invert sensor-level data to source space (i.e., estimate cortical current densities).\n",
    "4. Parcellate those sources into anatomically defined ROIs (Desikan-Killiany atlas).\n",
    "5. (Optionally) reshape the results back to an epoch-like structure for easier viewing.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# (Optional) Path setup for your project\n",
    "raw_data_path = '../data/raw/'\n",
    "source_path = '../data/source_reconstruction/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load EEG Epochs\n",
    "\n",
    "We load preprocessed EEG data stored in an EEGLAB `.set` file and convert it to an \n",
    "MNE `Epochs` object. This gives us a structured representation of the data with\n",
    "event-based segmentation (epochs).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = raw_data_path + 'PPT1/'\n",
    "input_fname = path + 's_101_Coordination.set'\n",
    "epochs = mne.io.read_epochs_eeglab(input_fname)\n",
    "print(epochs)\n",
    "\n",
    "# Subsample epochs to reduce memory usage (optional)\n",
    "# epochs = epochs[:5]  # e.g., only keep first 5 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.plot_sensors(kind='3d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set Montage\n",
    "\n",
    "We apply the standard 64-channel BioSemi montage to ensure that electrode positions are accurately mapped in 3D space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#montage = mne.channels.make_standard_montage('biosemi64')\n",
    "montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "epochs.set_montage(montage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Forward Solution\n",
    "\n",
    "A forward solution maps neural sources in the brain to the EEG electrodes. We use\n",
    "the MNE-supplied `fsaverage` template, which includes:\n",
    "- A source space (`ico-5`) describing dipole locations on the cortical mesh\n",
    "- A BEM model describing how currents propagate through the scalp/skull/brain\n",
    "- A standard head-to-MRI transform (`fsaverage`)\n",
    "\n",
    "This step produces a gain matrix that we'll later invert (via the inverse operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBJECTS_DIR = mne.datasets.fetch_fsaverage()\n",
    "SUBJECT = 'fsaverage'\n",
    "\n",
    "# If fetch_fsaverage() returns a path ending with \"fsaverage/fsaverage\",\n",
    "# move one directory up to get the correct SUBJECTS_DIR:\n",
    "if \"fsaverage\" in os.path.basename(SUBJECTS_DIR):\n",
    "    SUBJECTS_DIR = os.path.dirname(SUBJECTS_DIR)\n",
    "print(f\"Fsaverage directory is at: {SUBJECTS_DIR}\")\n",
    "\n",
    "# Standard transformation: 'fsaverage'\n",
    "trans = 'fsaverage'  \n",
    "\n",
    "# The source space & BEM files for fsaverage\n",
    "src = os.path.join(SUBJECTS_DIR, SUBJECT, 'bem', 'fsaverage-ico-5-src.fif') \n",
    "bem = os.path.join(SUBJECTS_DIR, SUBJECT, 'bem', 'fsaverage-5120-5120-5120-bem-sol.fif') \n",
    "\n",
    "# Build the forward solution (5 mm mindist from inner skull)\n",
    "fwd = mne.make_forward_solution(\n",
    "    info=epochs.info,\n",
    "    trans=trans,\n",
    "    src=src,\n",
    "    bem=bem,\n",
    "    eeg=True,\n",
    "    mindist=5.0,\n",
    "    n_jobs=4\n",
    ")\n",
    "\n",
    "print(fwd)\n",
    "\n",
    "# Save forward operator for reuse\n",
    "fwd_fname = os.path.join(source_path, 'fsaverage_64_fwd.fif')\n",
    "mne.write_forward_solution(fwd_fname, fwd, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_alignment(epochs.info, trans=trans, src=src, bem=bem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the locations of EEG electrodes is correct with respect to MRI\n",
    "mne.viz.plot_alignment(\n",
    "    epochs.info,\n",
    "    src=src,\n",
    "    eeg=[\"original\", \"projected\"],\n",
    "    trans=trans,\n",
    "    show_axes=True,\n",
    "    mri_fiducials=True,\n",
    "    dig=\"fiducials\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Re-loading the Forward Solution (if needed)\n",
    "\n",
    "In practice, you can load the saved forward solution instead of recomputing it \n",
    "each time. Here we show how to read it back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_fwd = os.path.join(source_path, 'fsaverage_64_fwd.fif')\n",
    "fwd = mne.read_forward_solution(fname_fwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_alignment(\n",
    "    epochs.info,\n",
    "    trans='fsaverage',\n",
    "    subject='fsaverage',\n",
    "    subjects_dir=SUBJECTS_DIR,\n",
    "    eeg=['original', 'projected'],\n",
    "    src=fwd['src']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Parcellation - Desikan-Killiany Atlas\n",
    "\n",
    "This atlas divides each hemisphere into 34 regions, giving 68 cortical ROIs total.\n",
    "\n",
    "The file `aparc.annot` is part of the FreeSurfer segmentation for `fsaverage`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mne.read_labels_from_annot(\n",
    "    subject=\"fsaverage\",\n",
    "    parc=\"aparc\",\n",
    "    subjects_dir=SUBJECTS_DIR\n",
    ")\n",
    "# Remove the \"unknown\" label\n",
    "labels = labels[:-1] \n",
    "label_names = [label.name for label in labels]\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain = mne.viz.get_brain_class()\n",
    "brain = Brain(\n",
    "    \"fsaverage\",\n",
    "    \"both\",\n",
    "    \"inflated\",\n",
    "    subjects_dir=SUBJECTS_DIR,\n",
    "    background=\"white\",\n",
    "    size=(800, 600),\n",
    ")\n",
    "brain.add_annotation(\"aparc\")\n",
    "brain.add_label(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Concatenate Epochs into One Raw\n",
    "\n",
    "To avoid computing large STCs for each epoch, we concatenate all epochs in time \n",
    "forming a single, continuous `Raw` object. We'll then apply the inverse \n",
    "solution on one label at a time, drastically reducing memory usage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Get data shape\n",
    "n_epochs, n_channels, n_times = epochs.get_data().shape\n",
    "print(f\"Epochs shape: {n_epochs} epochs, {n_channels} channels, {n_times} time points each\")\n",
    "\n",
    "# 2) Keep only EEG channels (drop EOG, etc. if any)\n",
    "epochs_eeg = epochs.copy().pick_types(eeg=True)\n",
    "\n",
    "# 3) Convert [n_epochs, n_channels, n_times] -> [n_channels, n_epochs * n_times]\n",
    "data_3d = epochs_eeg.get_data()  # shape (n_epochs, n_eeg_ch, n_times)\n",
    "data_2d = data_3d.transpose(1, 0, 2).reshape(n_channels, -1)\n",
    "print(f\"Data shape after conversion: {data_2d.shape}\")\n",
    "\n",
    "# 4) Create a RawArray with the same Info (for EEG channels only)\n",
    "info_eeg = epochs_eeg.info\n",
    "raw = mne.io.RawArray(data_2d, info_eeg)\n",
    "raw._filenames = [\"\"]  # to avoid warnings about missing filename\n",
    "raw.set_eeg_reference(projection=True)\n",
    "print(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Noise Covariance\n",
    "\n",
    "Here we use a simple **ad-hoc covariance** (diagonal with default noise values). \n",
    "\n",
    "It is possible too also use `mne.compute_covariance`, but that is applied for a baseline which we don't have here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_cov = mne.make_ad_hoc_cov(raw.info, None)\n",
    "print(\"Ad-hoc noise covariance diagonal:\\n\", noise_cov.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Construct the Inverse Operator\n",
    "\n",
    "Combining the forward model, noise covariance, and sensor info yields an inverse \n",
    "operator that we can use to reconstruct cortical sources from scalp measurements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_operator = mne.minimum_norm.make_inverse_operator(\n",
    "    info=raw.info,\n",
    "    forward=fwd,\n",
    "    noise_cov=noise_cov,\n",
    "    loose=1.0,    # free orientation\n",
    "    depth=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Obtain Time Series for Each ROI\n",
    "\n",
    "We loop over each Desikan-Killiany label, computing the inverse solution \n",
    "restricted to that subset of cortical vertices. This is memory-efficient \n",
    "because we never handle the entire cortex at once.\n",
    "\n",
    "- **`apply_inverse_raw(label=...)`**: Only solves for vertices in that label.\n",
    "- **PCA**: Reduces the 3D dipole orientations to a single principal axis.\n",
    "- **mean_flip**: Ensures consistent polarity so waveforms don't cancel out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_labels = len(labels)\n",
    "print(f\"Number of labels (ROIs): {n_labels}\")\n",
    "\n",
    "snr = 3.0\n",
    "lambda2 = 1.0 / snr**2\n",
    "\n",
    "# label_ts will store the final time courses: [n_labels, total_time_points]\n",
    "label_ts = np.zeros((n_labels, n_epochs * n_times))\n",
    "\n",
    "for li, label in enumerate(labels):\n",
    "    # Apply inverse for only these vertices\n",
    "    stc = mne.minimum_norm.apply_inverse_raw(\n",
    "        raw,\n",
    "        inverse_operator,\n",
    "        lambda2=lambda2,\n",
    "        method='MNE',\n",
    "        pick_ori='vector',  # unconstrained orientation\n",
    "        label=label,\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # PCA to collapse the 3 orientation components\n",
    "    stc_pca, pca_dir = stc.project(directions='pca', src=inverse_operator['src'])\n",
    "\n",
    "    # Extract the mean time course for this ROI\n",
    "    roi_data = mne.extract_label_time_course(\n",
    "        stc_pca, [label], inverse_operator['src'],\n",
    "        mode='mean_flip', return_generator=False, verbose=False\n",
    "    )\n",
    "    # Insert into array (roi_data[0] => shape = total_time_points)\n",
    "    label_ts[li, :] = roi_data[0, :]\n",
    "\n",
    "    # Free memory\n",
    "    del stc, stc_pca\n",
    "\n",
    "    # Progress logging\n",
    "    if (li+1) % 5 == 0:\n",
    "        print(f\"Processed {li+1} / {n_labels} labels\")\n",
    "\n",
    "print(\"All labels processed. Shape of label_ts:\", label_ts.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Plot of One ROI\n",
    "\n",
    "Here we just take one ROI (e.g., label index 20) and show its time course across \n",
    "the concatenated epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series of the first label\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(1e3 * label_ts[20, :])\n",
    "plt.xlabel(\"Time (ms)\")\n",
    "plt.ylabel(\"Mean source amplitude\")\n",
    "plt.title(f\"Mean source amplitude for {labels[0].name}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. (Optional) Reshape into Epochs\n",
    "\n",
    "If you want to restore the data to an epoch-like structure, we can reshape \n",
    "`[label, total_time] -> [epochs, label, time]`. Then we can use `mne.EpochsArray`\n",
    "to visualize it in MNE's usual epoch plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_ts_reshaped = label_ts.reshape(n_labels, n_epochs, n_times).transpose(1, 0, 2)\n",
    "print(\"New shape: \", label_ts_reshaped.shape)  # (n_epochs, n_labels, n_times)\n",
    "\n",
    "# Create an EpochsArray object for ROI-based signals\n",
    "info = mne.create_info(\n",
    "    ch_names=[lbl.name for lbl in labels],\n",
    "    sfreq=epochs.info['sfreq'],\n",
    "    ch_types='eeg'\n",
    ")\n",
    "label_epochs = mne.EpochsArray(\n",
    "    data=label_ts_reshaped,\n",
    "    info=info,\n",
    "    tmin=epochs.times[0],\n",
    "    verbose=False\n",
    ")\n",
    "# save the epochs\n",
    "label_epochs.save(os.path.join(source_path, 's101_Coordination-source-epo.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the ROI-level epochs\n",
    "label_epochs.plot(n_channels=10, n_epochs=5, scalings=\"auto\", title=\"ROI-level epochs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print label names\n",
    "print(label_names)\n",
    "print(epochs.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# label_ts has shape (n_labels, total_time)\n",
    "# 'labels' is a list of label objects\n",
    "# 'label_names' is the list of label names, or you can do [lbl.name for lbl in labels]\n",
    "\n",
    "roi_info = mne.create_info(\n",
    "    ch_names=[lbl.name for lbl in labels],    # e.g. \"cuneus-lh\", \"insula-rh\", ...\n",
    "    sfreq=epochs.info['sfreq'],\n",
    "    ch_types='eeg'  # treat each ROI time course as an EEG channel\n",
    ")\n",
    "\n",
    "roi_raw = mne.io.RawArray(label_ts, roi_info)\n",
    "roi_raw._filenames = [\"\"]  # to avoid filename warnings\n",
    "\n",
    "\n",
    "# Plot the sensor-level concatenated data\n",
    "raw.plot(\n",
    "    n_channels=10,   # how many channels to view at once\n",
    "    scalings='auto',\n",
    "    title='Sensor-level (Raw)'\n",
    ")\n",
    "\n",
    "# Plot the ROI-level data\n",
    "roi_raw.plot(\n",
    "    n_channels=10,\n",
    "    scalings='auto',\n",
    "    title='ROI-level (Raw)'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Choose an anatomically close pair ---\n",
    "sensor_name = 'P1'       # Sensor channel (from raw.ch_names)\n",
    "roi_name = 'superiorparietal-lh'   # ROI channel (from roi_raw.ch_names)\n",
    "\n",
    "# --- Extract data from raw objects ---\n",
    "sensor_idx = raw.ch_names.index(sensor_name)\n",
    "roi_idx = roi_raw.ch_names.index(roi_name)\n",
    "\n",
    "sensor_signal = raw.get_data(picks=[sensor_idx])[0]  # shape: (n_times,)\n",
    "roi_signal = roi_raw.get_data(picks=[roi_idx])[0]    # shape: (n_times,)\n",
    "\n",
    "# --- Time vector ---\n",
    "sfreq = raw.info['sfreq']\n",
    "n_times = sensor_signal.shape[0]\n",
    "time = np.arange(n_times) / sfreq  # in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Choose an anatomically close pair ---\n",
    "sensor_name = 'C1'       # Sensor channel (from raw.ch_names)\n",
    "roi_name = 'paracentral-lh'   # ROI channel (from roi_raw.ch_names)\n",
    "\n",
    "# --- Extract data from raw objects ---\n",
    "sensor_idx = raw.ch_names.index(sensor_name)\n",
    "\n",
    "roi_idx = roi_raw.ch_names.index(roi_name)\n",
    "\n",
    "sensor_signal = raw.get_data(picks=[sensor_idx])[0]  # shape: (n_times,)\n",
    "roi_signal = -roi_raw.get_data(picks=[roi_idx])[0]    # shape: (n_times,)\n",
    "\n",
    "# --- Time vector ---\n",
    "sfreq = raw.info['sfreq']\n",
    "n_times = sensor_signal.shape[0]\n",
    "time = np.arange(n_times) / sfreq  # in seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot side-by-side ---\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6), sharex=True)\n",
    "\n",
    "axes[0].plot(time, sensor_signal, color='blue')\n",
    "axes[0].set_ylabel('Sensor amplitude (ÂµV)')\n",
    "axes[0].set_title(f'Sensor-level signal: {sensor_name}')\n",
    "\n",
    "axes[1].plot(time, roi_signal, color='green')\n",
    "axes[1].set_ylabel('Source amplitude (nAm)')\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_title(f'Source-level signal: {roi_name}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "sensor_signal_norm = zscore(sensor_signal)\n",
    "roi_signal_norm = zscore(roi_signal)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(time, sensor_signal_norm, label=f'{sensor_name} (Sensor)', linewidth=2)\n",
    "plt.plot(time, roi_signal_norm, label=f'{roi_name} (ROI)', linewidth=2)\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-scored amplitude')\n",
    "plt.title('Normalized ROI vs Sensor waveforms')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook demonstrates a **memory-efficient** approach to EEG source \n",
    "reconstruction in MNE using a template subject (`fsaverage`). We:\n",
    "\n",
    "1. Loaded epochs from EEGLAB format.\n",
    "2. Set a 64-channel standard montage.\n",
    "3. Computed (and saved) a forward solution.\n",
    "4. **Looped label-by-label** to apply the inverse, reducing memory usage.\n",
    "5. Extracted label time series and optionally reshaped them for epoch-style plotting.\n",
    "\n",
    "From here, you could:\n",
    "- Compute power spectra in each ROI,\n",
    "- Investigate connectivity between ROIs,\n",
    "- or visualize full-brain STCs for single epochs if you want 3D interactive plots \n",
    "  (by not restricting to `label=...` in `apply_inverse_raw`).\n",
    "\n",
    "Happy analyzing!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirror",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
